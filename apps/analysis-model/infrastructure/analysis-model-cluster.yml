AWSTemplateFormatVersion: '2010-09-09'
Description: ECS Cluster with Auto Scaling EC2 Instances for custom analysis processing

Parameters:
  VPCId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID
  PublicSubnet5:
    Type: AWS::EC2::Subnet::Id
    Description: Public Subnet 5 ID
  PublicSubnet6:
    Type: AWS::EC2::Subnet::Id
    Description: Public Subnet 6 ID
  ECSAMI:
    Type: String # AWS::SSM::Parameter::Value<AWS::EC2::Image::Id> (string bc nested stack)
    Description: ECS-optimized AMI ID
  InstanceType:
    Type: String
    Description: EC2 instance type
  EC2KeyPairName:
    Type: String
    Description: EC2 key pair name for the instances
  MinSize:
    Type: Number
    Description: Minimum number of EC2 instances in the Auto Scaling Group
  MaxSize:
    Type: Number
    Description: Maximum number of EC2 instances in the Auto Scaling Group
  DesiredCapacity:
    Type: Number
    Description: Desired number of EC2 instances in the Auto Scaling Group
  TargetBacklogPerTask:
    Type: Number
    Description: This is the ideal number of messages in backlog to be processed per task and it should be calculated by dividing the acceptable latency for a job completion by the average processing time of that job. For example if it is acceptable to wait 300 seconds for a job completion and it usually takes 10 seconds to complete the job than the target backlog per task = 300 / 10 = 30. This means that if we have 30 messages we want 1 task running, 60 messages we want 2 tasks running and so on. The lower the acceptable latency the fewer messages will be needed to trigger a scale out event and vice versa.
  AnalysisModelECRRepositoryName:
    Type: String
    Description: Name of the analysis model ECR repository
  AnalysisModelImageTag:
    Type: String
    Description: Tag of the analysis model Docker image to deploy
  CustomAnalysisQueueUrl:
    Type: String
    Description: URL of the Custom Analysis SQS Queue
  CustomAnalysisQueueName:
    Type: String
    Description: Arn of the Custom Analysis SQS Queue
  CustomAnalysisQueueArn:
    Type: String
    Description: Arn of the Custom Analysis SQS Queue
  VideoStorageS3BucketName:
    Type: String
    Description: Name of the S3 bucket that will store uploaded videos
  StackName:
    Type: String
    Description: Name of the parent stack

Resources:
  AnalysisModelCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: AnalysisModelCluster
      ClusterSettings:
        - Name: containerInsights
          Value: enabled

  AnalysisModelLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          full_install: [install_deps, verify_instance_health, signal_cfn]
        # Install dependencies
        install_deps:
          commands:
            InstallDependencies:
              command: |
                yum install -y awscli jq
        # Check the ECS API to see if this instance is available as capacity
        # inside of the ECS cluster, and wait for it to run the healthiness daemon
        verify_instance_health:
          commands:
            ECSHealthCheck:
              command: |
                echo "Introspecting ECS agent status"
                find_container_instance_arn() {
                  CONTAINER_INSTANCE_ARN=$(curl --connect-timeout 1 --max-time 1 -s http://localhost:51678/v1/metadata | jq -r '.ContainerInstanceArn')
                }
                find_container_instance_arn
                while [ "$CONTAINER_INSTANCE_ARN" == "" ]; do sleep 2; find_container_instance_arn; done
                echo "Container Instance ARN: $CONTAINER_INSTANCE_ARN"

                echo "Waiting for at least one running task"
                count_instance_tasks() {
                  NUMBER_OF_TASKS=$(curl -s http://localhost:51678/v1/tasks | jq '.Tasks | length')
                }
                count_instance_tasks
                while [ $NUMBER_OF_TASKS -lt 1 ]; do sleep 2; count_instance_tasks; done

                echo "Instance $CONTAINER_INSTANCE_ARN is now hosting $NUMBER_OF_TASKS task(s)"
        # This signals back to CloudFormation once the instance has become healthy in ECS
        # and has started hosting at least one task
        signal_cfn:
          commands:
            SignalCloudFormation:
              command: !Sub |
                /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackId} --resource AnalysisModelAutoScalingGroup --region ${AWS::Region}
    Properties:
      LaunchTemplateData:
        ImageId: !Ref ECSAMI
        InstanceType: !Ref InstanceType
        KeyName: !Ref EC2KeyPairName
        SecurityGroupIds:
          - !GetAtt AnalysisModelEC2SecurityGroup.GroupId
        IamInstanceProfile:
          Arn: !GetAtt AnalysisModelEC2InstanceProfile.Arn
        BlockDeviceMappings:
          - DeviceName: /dev/xvda
            Ebs:
              VolumeSize: 60
              VolumeType: gp3
        UserData:
          Fn::Base64: !Sub |
            #!/bin/bash -xe
            echo ECS_CLUSTER=${AnalysisModelCluster} >> /etc/ecs/ecs.config
            echo ECS_AVAILABLE_LOGGING_DRIVERS='["json-file","awslogs"]' >> /etc/ecs/ecs.config
            echo ECS_ENABLE_GPU_SUPPORT=true >> /etc/ecs/ecs.config
            yum install -y aws-cfn-bootstrap
            /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource AnalysisModelAutoScalingGroup --region ${AWS::Region}
            /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource AnalysisModelAutoScalingGroup --region ${AWS::Region}

  AnalysisModelEC2InstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - !Ref AnalysisModelEC2Role

  AnalysisModelEC2SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for ECS instances
      VpcId: !Ref VPCId
      SecurityGroupEgress:
        - IpProtocol: tcp
          FromPort: 0
          ToPort: 65535
          CidrIp: 0.0.0.0/0

  # Role for the EC2 hosts. This allows the ECS agent on the EC2 hosts
  # to communicate with the ECS control plane, as well as download the docker
  # images from ECR to run on your host.
  AnalysisModelEC2Role:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          # Allow the EC2 instances to assume this role
          - Effect: Allow
            Principal:
              Service: [ec2.amazonaws.com]
            Action: ['sts:AssumeRole']
      Path: /
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role
      Policies:
        - PolicyName: SQSAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'sqs:ReceiveMessage'
                  - 'sqs:DeleteMessage'
                  - 'sqs:GetQueueAttributes'
                Resource: !Ref CustomAnalysisQueueArn
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:HeadObject'
                  - 's3:ListBucket'
                Resource:
                  - !Sub arn:aws:s3:::${VideoStorageS3BucketName}/*
                  - !Sub arn:aws:s3:::${VideoStorageS3BucketName}

  # This is a role which is used within Fargate to allow the Fargate agent
  # to download images, and upload logs.
  AnalysisModelTaskExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service: [ecs-tasks.amazonaws.com]
            Action: ['sts:AssumeRole']
            Condition:
              ArnLike:
                aws:SourceArn: !Sub arn:aws:ecs:${AWS::Region}:${AWS::AccountId}:*
              StringEquals:
                aws:SourceAccount: !Ref AWS::AccountId
      Path: /

      # This role enables basic features of ECS. See reference:
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy

  AnalysisModelTaskDefinition:
    Type: AWS::ECS::TaskDefinition
    Properties:
      Family: analysis-model-and-poller-task
      NetworkMode: bridge
      RequiresCompatibilities:
        - EC2
      Cpu: '10240' # 10 of 16 vCPUs available in g4dn.4xlarge (its the max value accepted)
      Memory: '58982' # 90% of the 64GB available in g4dn.4xlarge
      ContainerDefinitions:
        - Name: analysis-model-container
          Image: !Sub ${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/${AnalysisModelECRRepositoryName}:${AnalysisModelImageTag}
          MemoryReservation: 58982
          Cpu: 10240
          Environment:
            - Name: SQS_QUEUE_URL
              Value: !Ref CustomAnalysisQueueUrl
          ResourceRequirements:
            - Type: GPU
              Value: 1
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-group: !Ref AnalysisModelCloudWatchLogsGroup
              awslogs-region: !Ref AWS::Region
              awslogs-stream-prefix: ecs

  AnalysisModelCloudWatchLogsGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: /ecs/analysis-model
      RetentionInDays: 14
    DeletionPolicy: Delete
    UpdateReplacePolicy: Retain

  AnalysisModelService:
    Type: AWS::ECS::Service
    Properties:
      ServiceName: AnalysisModelService
      Cluster: !Ref AnalysisModelCluster
      TaskDefinition: !Ref AnalysisModelTaskDefinition
      DesiredCount: !Ref DesiredCapacity # same as EC2 instances (1-1 relationship)
      PlacementStrategies:
        - Type: spread
          Field: attribute:ecs.availability-zone
        - Type: binpack
          Field: cpu
      CapacityProviderStrategy:
        - Base: !Ref DesiredCapacity
          CapacityProvider: !Ref AnalysisModelCapacityProvider
          Weight: 1
      DeploymentConfiguration:
        MaximumPercent: 200
        MinimumHealthyPercent: 100

  # Create an ECS capacity provider to attach the ASG to the Analysis Model cluster
  # so that it auto scales as we launch more tasks
  AnalysisModelCapacityProvider:
    Type: AWS::ECS::CapacityProvider
    Properties:
      AutoScalingGroupProvider:
        AutoScalingGroupArn: !Ref AnalysisModelAutoScalingGroup
        ManagedScaling:
          InstanceWarmupPeriod: 60
          MinimumScalingStepSize: 1
          MaximumScalingStepSize: 1
          Status: ENABLED
          # Percentage of cluster reservation to try to maintain
          TargetCapacity: 100
        ManagedTerminationProtection: DISABLED
        ManagedDraining: ENABLED

  # Create a cluster capacity provider association so that the cluster
  # will use the capacity provider
  AnalysisModelCapacityProviderAssociation:
    Type: AWS::ECS::ClusterCapacityProviderAssociations
    Properties:
      CapacityProviders:
        - !Ref AnalysisModelCapacityProvider
      Cluster: !Ref AnalysisModelCluster
      DefaultCapacityProviderStrategy:
        - Base: 0
          CapacityProvider: !Ref AnalysisModelCapacityProvider
          Weight: 1

  AnalysisModelAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn:
      - AnalysisModelCluster
      - AnalysisModelEC2Role
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: 1
        MaxBatchSize: 2
        PauseTime: PT2M
        WaitOnResourceSignals: true
        MinSuccessfulInstancesPercent: 100
    Properties:
      AutoScalingGroupName: AnalysisModelInstances
      VPCZoneIdentifier:
        - !Ref PublicSubnet5 # set to private subnets in production
        - !Ref PublicSubnet6 # using public to additional costs
      LaunchTemplate:
        LaunchTemplateId: !Ref AnalysisModelLaunchTemplate
        Version: !GetAtt AnalysisModelLaunchTemplate.LatestVersionNumber
      MinSize: !Ref MinSize
      MaxSize: !Ref MaxSize
      NewInstancesProtectedFromScaleIn: false
      Tags:
        - Key: Name
          Value: AnalysisModelInstances
          PropagateAtLaunch: true

  AnalysisModelServiceAutoScalingRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service: application-autoscaling.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceAutoscaleRole

  AnalysisModelServiceScalableTarget:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Properties:
      MaxCapacity: !Ref MaxSize # Correlate to ec2 max
      MinCapacity: !Ref MinSize # Correlate to ec2 min
      ResourceId: !Join
        - /
        - - service
          - !Ref AnalysisModelCluster
          - !GetAtt AnalysisModelService.Name
      RoleARN: !GetAtt AnalysisModelServiceAutoScalingRole.Arn
      ScalableDimension: ecs:service:DesiredCount
      ServiceNamespace: ecs

  #
  # SQS-based auto scaling: Backlog per task custom metric
  #

  # The custom Lambda function extracts key metrics, such as the number of messages
  # in the SQS queue and the current tasks in the ECS service, then calculates the
  # current backlog per task. This function runs at regular intervals to provide
  # real-time data for scaling decisions.
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: EcsSqsMetricsPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - sqs:GetQueueAttributes
                  - ecs:DescribeServices
                  - cloudwatch:PutMetricData
                  - application-autoscaling:RegisterScalableTarget
                  - application-autoscaling:DescribeScalableTargets
                  - application-autoscaling:DeregisterScalableTarget
                Resource: '*'

  MetricsLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: |
          import os
          import boto3

          def lambda_handler(event, context):
              sqs = boto3.client('sqs')
              ecs = boto3.client('ecs')
              cloudwatch = boto3.client('cloudwatch')
              autoscaling = boto3.client('application-autoscaling')
              
              queue_url = os.environ['QUEUE_URL']
              cluster_name = os.environ['CLUSTER_NAME']
              service_name = os.environ['SERVICE_NAME']
              target_backlog_per_task = int(os.environ['TARGET_BACKLOG_PER_TASK'])
              
              # Get SQS queue attributes
              queue_attrs = sqs.get_queue_attributes(
                  QueueUrl=queue_url,
                  AttributeNames=['ApproximateNumberOfMessages']
              )
              approx_messages = int(queue_attrs['Attributes']['ApproximateNumberOfMessages'])
              
              # Get number of active tasks in ECS service
              service_desc = ecs.describe_services(
                  cluster=cluster_name,
                  services=[service_name]
              )
              active_tasks = service_desc['services'][0]['runningCount']

              # Calculate backlog per task
              if approx_messages == 0:
                  backlog_per_task = 0; # Scale to zero
              elif approx_messages < target_backlog_per_task * 0.9:
                  # Prevent target tracking from scaling to zero (we don't want any messages unprocessed). The scale from zero alarm will provision 1 instance
                  backlog_per_task = target_backlog_per_task * 0.9
              elif active_tasks > 0:
                  backlog_per_task = approx_messages / active_tasks
              else: # No tasks and at least 90% of target backlog
                  backlog_per_task = approx_messages
              
              # Put custom metric data
              cloudwatch.put_metric_data(
                  Namespace='CustomDemo/ECS/SQS',
                  MetricData=[
                      {
                          'MetricName': 'backlogPerTask',
                          'Dimensions': [
                              {'Name': 'ClusterName', 'Value': cluster_name},
                              {'Name': 'ServiceName', 'Value': service_name}
                          ],
                          'Value': backlog_per_task,
                          'Unit': 'Count'
                      }
                  ]
              )
              
              print(f"Approximate messages: {approx_messages}")
              print(f"Active tasks: {active_tasks}")
              print(f"Backlog per task: {backlog_per_task}")
              
              return {
                  'statusCode': 200,
                  'body': 'Metrics updated successfully'
              }
      Runtime: python3.12
      Timeout: 30
      LoggingConfig:
        LogGroup: !Ref MetricsLambdaCloudWatchLogsGroup
      Environment:
        Variables:
          QUEUE_URL: !Ref CustomAnalysisQueueUrl
          CLUSTER_NAME: AnalysisModelCluster
          SERVICE_NAME: AnalysisModelService
          TARGET_BACKLOG_PER_TASK: !Ref TargetBacklogPerTask
    DeletionPolicy: Delete

  MetricsLambdaCloudWatchLogsGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: /lambda/metrics
      RetentionInDays: 14
    DeletionPolicy: Delete
    UpdateReplacePolicy: Retain

  MetricsLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref MetricsLambdaFunction
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt MetricsScheduleRule.Arn

  MetricsScheduleRule:
    Type: AWS::Events::Rule
    Properties:
      Description: Schedule for invoking the Metrics Lambda function
      ScheduleExpression: rate(1 minute)
      State: ENABLED
      Targets:
        - Arn: !GetAtt MetricsLambdaFunction.Arn
          Id: MetricsLambdaFunction

  ScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: SqsQueueTrackingPolicy
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref AnalysisModelServiceScalableTarget
      TargetTrackingScalingPolicyConfiguration:
        CustomizedMetricSpecification:
          MetricName: backlogPerTask
          Namespace: CustomDemo/ECS/SQS
          Dimensions:
            - Name: ClusterName
              Value: AnalysisModelCluster
            - Name: ServiceName
              Value: AnalysisModelService
          Statistic: Average
        TargetValue: !Ref TargetBacklogPerTask
        ScaleInCooldown: 60
        ScaleOutCooldown: 60

  # Its possible to only use target tracking to scale from zero as soon as we have 1
  # message by setting the backlog metric to the target backlog BUT it will scale too
  # aggressively (jumping right to 2 instances instead of just 1) which is unnecessary and
  # can become expensive with G type instances like in this case, so we'll add a scale from
  # zero policy to be more conservative
  ScaleFromZeroPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: ScaleFromZeroPolicy
      PolicyType: StepScaling
      ScalingTargetId: !Ref AnalysisModelServiceScalableTarget
      StepScalingPolicyConfiguration:
        AdjustmentType: ExactCapacity
        MetricAggregationType: Average
        Cooldown: 60
        StepAdjustments:
          - MetricIntervalLowerBound: 0
            ScalingAdjustment: 1

  ScaleFromZeroAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: ScaleFromZeroAlarm
      AlarmDescription: Alarm to trigger scaling from zero when SQS queue length is greater than zero and less than or equal to target
      Metrics:
        - Id: visibleMessages
          MetricStat:
            Metric:
              Namespace: AWS/SQS
              MetricName: ApproximateNumberOfMessagesVisible
              Dimensions:
                - Name: QueueName
                  Value: !Ref CustomAnalysisQueueName
            Period: 60
            Stat: Sum
          ReturnData: false
        - Id: greaterThanZero
          Expression: visibleMessages > 0
          Label: MessagesGreaterThanZero
          ReturnData: false
        - Id: withinThreshold
          Expression: !Sub visibleMessages <= ${TargetBacklogPerTask}
          Label: MessagesWithinTarget
          ReturnData: false
        - Id: combinedCondition
          Expression: greaterThanZero AND withinThreshold
          Label: ValidBacklogCondition
          ReturnData: true
      EvaluationPeriods: 1
      DatapointsToAlarm: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      TreatMissingData: notBreaching
      AlarmActions:
        - !Ref ScaleFromZeroPolicy

  # Because we are launching tasks in AWS VPC networking mode
  # the tasks themselves also have an extra security group that is unique
  # to them. This is a unique security group just for this service,
  # to control which things it can talk to, and who can talk to it
  AnalysisModelServiceSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: !Sub Access to service ${AnalysisModelService}
      VpcId: !Ref VPCId

Outputs:
  AnalysisModelCluster:
    Description: A reference to the Analysis Model ECS cluster
    Value: !Ref AnalysisModelCluster
    Export:
      Name: !Sub ${StackName}-AnalysisModelCluster

  AnalysisModelServiceName:
    Description: Name of the Analysis Model ECS Service
    Value: !GetAtt AnalysisModelService.Name
    Export:
      Name: !Sub ${StackName}-AnalysisModelServiceName

  AnalysisModelCapacityProvider:
    Description:
      The Analysis Model cluster capacity provider that the service should use
      to request capacity when it wants to start up a task
    Value: !Sub ${StackName}-AnalysisModelCapacityProvider

  AnalysisModelTaskDefinitionArn:
    Description: ARN of the Analysis Model Task Definition
    Value: !Ref AnalysisModelTaskDefinition
    Export:
      Name: !Sub ${StackName}-AnalysisModelTaskDefinitionArn
